# Test Description
#
# We start and stop the Backup and restore process multiple times. This should not influence the backup

- name: coyote
  title: kafka-backup

- name: Setup Cluster to Backup
  entries:
    - name: Docker Compose Up
      timeout: 300s
      command: docker-compose up -d
    - name: Clean previous data
      command: docker run -v /tmp/kafka-backup/:/kafka-backup/ kafka-backup-dev:latest rm -rf "/kafka-backup/03_start_n_stop/"
    - name: Wait for Kafka to get up
      command: docker logs to-backup-kafka 2>&1 | grep -q '\[KafkaServer id=1\] started'
      timeout: 30s

- name: Setup Tests
  entries:
    - name: Create Topics
      command: docker-compose exec -T to-backup-kafka runutil bash -c '
        create_topic backup-test-1partition 1 &&
        create_topic backup-test-3partitions 3'
      timeout: 300s
    - name: Produce 300 messages, 10KiB each to each partition
      timeout: 300s
      command: docker-compose exec -T to-backup-kafka runutil bash -c '
        produce_messages backup-test-1partition 0 0 300 &&

        produce_messages backup-test-3partitions 0 0 300 &&
        produce_messages backup-test-3partitions 1 0 300 &&
        produce_messages backup-test-3partitions 2 0 300'
    - name: Consume all messages with consumer-group `cg-3k`
      timeout: 300s
      command: docker-compose exec -T to-backup-kafka runutil bash -c '
        consume_messages backup-test-1partition cg-3k 300 &&
        consume_messages backup-test-3partitions cg-3k 900'

- name: Start Kafka Backup
  entries:
    - name: Start Kafka Backup
      command: >
        docker run -d -v /tmp/kafka-backup/:/kafka-backup/ --net=system_test_to-backup --name to-backup --rm
        kafka-backup-dev:latest backup-standalone.sh --bootstrap-server to-backup-kafka:9092
        --target-dir /kafka-backup/03_start_n_stop/ --topics-regex 'backup-test.*' --max-segment-size 10485760
    - command: sleep 10
      nolog: true
    - name: Check For errors
      timeout: 300s
      command: docker exec to-backup curl -vs "http://localhost:8083/connectors/backup-sink/status"
      stderr_has: ["200 OK"]
      stdout_has: ["RUNNING"]
      stdout_not_has: ["FAILED"]

- name: Restart Kafka Backup and Produce more data
  entries:
    - name: Stop Kafka Backup
      command: docker kill to-backup
    - command: sleep 10
      nolog: true
    - name: Produce 300 messages, 10KiB each to each partition
      timeout: 300s
      command: docker-compose exec -T to-backup-kafka runutil bash -c '
        produce_messages backup-test-1partition 0 300 300 &&

        produce_messages backup-test-3partitions 0 300 300 &&
        produce_messages backup-test-3partitions 1 300 300 &&
        produce_messages backup-test-3partitions 2 300 300'
    - name: Start Kafka Backup
      command: >
        docker run -d -v /tmp/kafka-backup/:/kafka-backup/ --net=system_test_to-backup --name to-backup --rm
        kafka-backup-dev:latest backup-standalone.sh --bootstrap-server to-backup-kafka:9092
        --target-dir /kafka-backup/03_start_n_stop/ --topics-regex 'backup-test.*' --max-segment-size 10485760
    - command: sleep 10
      nolog: true
    - name: Pause Kafka Backup
      command: >
        docker exec to-backup
        curl -s -X PUT "http://localhost:8083/connectors/backup-sink/pause"
    - command: sleep 10
      nolog: true
    - name: Produce 300 messages, 10KiB each to each partition
      timeout: 300s
      command: docker-compose exec -T to-backup-kafka runutil bash -c '
        produce_messages backup-test-1partition 0 600 300 &&

        produce_messages backup-test-3partitions 0 600 300 &&
        produce_messages backup-test-3partitions 1 600 300 &&
        produce_messages backup-test-3partitions 2 600 300'
    - name: Produce 300 messages to 1partition to force segmentation roll
      timeout: 300s
      command: docker-compose exec -T to-backup-kafka runutil
        produce_messages backup-test-1partition 0 600 300
    - name: Start Kafka Backup
      command: >
        docker exec to-backup
        curl -s -X PUT "http://localhost:8083/connectors/backup-sink/resume"
    - command: sleep 10
      nolog: true

- name: Stop Cluster that was backed up
  entries:
    - name: Stop Kafka Backup
      command: docker kill to-backup
    - name: Docker Compose Down
      timeout: 300s
      command: docker-compose stop to-backup-kafka

- name: Restore
  entries:
    - name: Create Topic
      timeout: 300s
      command: docker-compose exec -T restore-to-kafka runutil bash -c '
        create_topic backup-test-1partition 1 &&
        create_topic backup-test-3partitions 3'
    - name: Run Kafka Restore
      command: >
        docker run -v /tmp/kafka-backup/:/kafka-backup/ --net=system_test_restore-to --name restore-to --rm
        kafka-backup-dev:latest restore-standalone.sh --bootstrap-server restore-to-kafka:9092
        --source-dir /kafka-backup/03_start_n_stop/
        --topics 'backup-test-1partition,backup-test-3partitions'
      timeout: 60s
      stdout_has: ['All records read.']

- name: Verify Backup
  entries:
    - name: Verify Records of backup-test-1partition
      timeout: 300s
      command: docker-compose exec -T restore-to-kafka runutil
        consume_verify_messages backup-test-1partition 0 900
    - name: Verify Records of backup-test-3partitions
      timeout: 300s
      command: |
        docker-compose exec -T restore-to-kafka runutil bash -c '
          for i in $(seq 0 2) ; do
              consume_verify_messages backup-test-3partitions $i 900
          done'
    - name: Check Consumer Group cg-3k
      timeout: 300s
      command: docker-compose exec -T restore-to-kafka runutil
        kafka_group_describe cg-3k
      stdout_has: [
        'backup-test-1partition  0          300',
        'backup-test-3partitions 0          300',
        'backup-test-3partitions 1          300',
        'backup-test-3partitions 2          300']
- name: Clean-up Containers
  entries:
    - name: Docker Compose Down
      command: docker-compose down
